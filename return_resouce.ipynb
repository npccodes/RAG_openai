{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7738dc71-cecc-46d1-8b10-5c395f2f5fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\OpenAI\\RAG_openai\\RAG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import bs4\n",
    "import langchain\n",
    "import langchain_community\n",
    "import langchain_core\n",
    "import langchain_openai\n",
    "import lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b93963-3bc6-4a98-bbdd-dbb7c6d833ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores.lancedb import LanceDB\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87f9597-7d6f-4b2c-b677-1cce4777f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = lancedb.connect(\"/temp/lancedb\")\n",
    "vector_table = vectordb.create_table(\"my_table\",\n",
    "                                    data = [{\n",
    "            \"vector\": OpenAIEmbeddings().embed_query(\"Hello World\"),\n",
    "            \"text\": \"Hello World\",\n",
    "            \"id\": \"1\",\n",
    "        }], mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d7da8e-9cac-427f-8d9f-a4dae8c17ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_strainer = bs4.SoupStrainer(class_ = (\"post-content\", \"post-title\", \"post-header\"))  \n",
    "loader = WebBaseLoader(web_path=\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "                       bs_kwargs=dict(parse_only = bs_strainer)\n",
    "                      )\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df68f79d-bbed-44e8-95c7-3eae5d11a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 800, chunk_overlap = 250)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorStore = LanceDB.from_documents(documents=splits, embedding=OpenAIEmbeddings(), connection = vector_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6b1319-12c9-4154-b8a6-b68ef80cfd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorStore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28295447-0984-45f9-9c3a-52403dee329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"/n/n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c362b4fd-09e9-4b02-a0e8-b0eb8c044bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(context = (lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aebad3f1-e9d8-4588-badd-3fe31449e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_with_resource = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\" : RunnablePassthrough()}\n",
    ").assign(answer = rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f43f7146-85df-4595-b081-65f2dda93621",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rag_chain_with_resource.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be06850d-11e6-4272-9953-3b29cde6f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', metadata={'vector': array([-0.0051782 ,  0.00363057,  0.01988922, ..., -0.00395657,\n",
       "         -0.01623806, -0.02603854], dtype=float32), 'id': '0b7a54c8-24c8-4b71-8574-f4ff60bc42bc', '_distance': 0.3309714198112488}),\n",
       "  Document(page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'vector': array([-0.00555773,  0.00050857,  0.02258861, ..., -0.00183997,\n",
       "         -0.01573774, -0.04845132], dtype=float32), 'id': 'ffbcfd30-c727-4655-8fa6-3d82d9ea7dc1', '_distance': 0.3469965159893036}),\n",
       "  Document(page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use', metadata={'vector': array([-0.02218482,  0.01165932,  0.04079055, ..., -0.00415282,\n",
       "         -0.01841449, -0.02909708], dtype=float32), 'id': 'f25b2841-1766-4eba-b9c2-1688f8a1bbce', '_distance': 0.41211992502212524}),\n",
       "  Document(page_content='Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:', metadata={'vector': array([-0.00691378, -0.00157609,  0.00923938, ..., -0.00671414,\n",
       "         -0.00951958, -0.024615  ], dtype=float32), 'id': '2a57ac75-bf48-4d9a-a970-615a0bb880fb', '_distance': 0.43179404735565186})],\n",
       " 'question': 'What is Task Decomposition?',\n",
       " 'answer': 'Task decomposition is the process of breaking down a complex task into smaller, manageable subgoals or steps. It allows an agent to plan ahead and handle complex tasks more efficiently. Task decomposition can be done through various methods, such as using prompting techniques, task-specific instructions, or human inputs.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b097efcf-74f3-4bbc-bffb-767953efa9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down a complex task into smaller, manageable subgoals or steps. It allows an agent to plan ahead and handle complex tasks more efficiently. Task decomposition can be done through various methods, such as using prompting techniques, task-specific instructions, or human inputs.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "442f2803-a281-4d72-88e0-de0a40953367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\n",
      "\n",
      "\n",
      "Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n"
     ]
    }
   ],
   "source": [
    "for doc in res['context']:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ecba6-e220-4c1d-b777-0b62daef97ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
